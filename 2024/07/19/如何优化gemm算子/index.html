<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>如何优化gemm算子 - lcy&#039;s blog</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="rgba(99, 187, 208, 0.9)"><meta name="application-name" content="lcy&#039;s blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="msapplication-TileColor" content="rgba(99, 187, 208, 0.9)"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="lcy&#039;s blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="最近在做开源之下的项目，记录一下学习 gemm 的优化过程。"><meta property="og:type" content="blog"><meta property="og:title" content="如何优化gemm算子"><meta property="og:url" content="http://example.com/2024/07/19/%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96gemm%E7%AE%97%E5%AD%90/"><meta property="og:site_name" content="lcy&#039;s blog"><meta property="og:description" content="最近在做开源之下的项目，记录一下学习 gemm 的优化过程。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://example.com/2024/07/19/%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96gemm%E7%AE%97%E5%AD%90/1.svg"><meta property="og:image" content="http://example.com/2024/07/19/%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96gemm%E7%AE%97%E5%AD%90/2.svg"><meta property="og:image" content="http://example.com/2024/07/19/%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96gemm%E7%AE%97%E5%AD%90/3.svg"><meta property="article:published_time" content="2024-07-19T03:12:35.000Z"><meta property="article:modified_time" content="2024-07-19T03:28:07.801Z"><meta property="article:author" content="lcy"><meta property="article:tag" content="ospp"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/2024/07/19/%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96gemm%E7%AE%97%E5%AD%90/1.svg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2024/07/19/%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96gemm%E7%AE%97%E5%AD%90/"},"headline":"如何优化gemm算子","image":[],"datePublished":"2024-07-19T03:12:35.000Z","dateModified":"2024-07-19T03:28:07.801Z","author":{"@type":"Person","name":"lcy"},"publisher":{"@type":"Organization","name":"lcy's blog","logo":{"@type":"ImageObject","url":"http://example.com/img/favicon.svg"}},"description":"最近在做开源之下的项目，记录一下学习 gemm 的优化过程。"}</script><link rel="canonical" href="http://example.com/2024/07/19/%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96gemm%E7%AE%97%E5%AD%90/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="lcy's blog" type="application/atom+xml">
</head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/favicon.svg" alt="lcy&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-07-19T03:12:35.000Z" title="7/19/2024, 11:12:35 AM">2024-07-19</time>发表</span><span class="level-item"><time dateTime="2024-07-19T03:28:07.801Z" title="7/19/2024, 11:28:07 AM">2024-07-19</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/public/">public</a></span><span class="level-item">24 分钟读完 (大约3536个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">如何优化gemm算子</h1><div class="content"><p>最近在做开源之下的项目，记录一下学习 gemm 的优化过程。</p>
<span id="more"></span>
<p>gemm 即矩阵乘法，通常的 gemm 可表示为一个 MxK 的矩阵 A 和一个 KxN 的矩阵 B 相乘得到一个 MxN 的矩阵 C。矩阵计算的优化思路可以总结为以下几步，在这个博客中省去了对计算机组成原理的一些介绍。</p>
<h2 id="优化思路"><a class="markdownIt-Anchor" href="#优化思路">#</a> 优化思路</h2>
<ol>
<li>
<p><strong>Split MNK</strong></p>
<p>这一步优化主要是<strong>基于计算机体系架构的 cache 结构，节省计算数据在 cache 和内存间读取的时间</strong>。<br>
切分 MNK（根据 L1 cache 的大小），比如 arm64 中 FP32M8N12 就是将矩阵 A（MxK）切分为若干个（8xK）矩阵，将矩阵 B（KxN）切分为若干个（Kx12）的矩阵，在第 2 步中提到了为何这么切分。</p>
</li>
<li>
<p><strong>分层计算</strong></p>
<p>这一步优化主要是<strong>节省中间数据在内存和 cache 之间换入换出</strong>的时间。<br>
传统的 MNK 矩阵切分计算后，应该是 A 的小矩阵的每一<strong>行</strong>乘上 B 的小矩阵的每一<strong>列</strong>，这种做法比较低效，且存在很多冗余的重复加载。<br>
分层计算的核心是每次用 A 的小矩阵的每一<strong>列</strong>（8 个元素，1X8 矩阵）和 B 的小矩阵的每一<strong>行</strong>（12 个元素，12X1 矩阵）相乘，得到中间结果矩阵（一层 8x12 矩阵），在这个过程中，把每一个中间结果矩阵累加，就得到了小矩阵 8K 和小矩阵 K12 计算的结果（完整 8x12 矩阵）。<br>
以 arm64 架构的 CPU 为例子，有 32 个 128 位的 neon 向量寄存器，那么 M8N12 的每次分层计算中，A 需要从内存中读取 8 个元素，占用 2 个寄存器；B 需要从内存中读取 12 个元素，占用 3 个寄存器；C（中间结果）的形状为 8x12，需要占用 24 个寄存器来累加运算。</p>
</li>
<li>
<p><strong>SIMD 优化</strong></p>
<p>这一步优化主要是<strong>通过并行计算提高数据运算的速度</strong>。在 cache 计算中使用 SIMD 优化，并行计算元素与元素相乘的过程。</p>
</li>
<li>
<p><strong>内存重排（pack）</strong></p>
<p>这一步的优化主要是<strong>节省数据在内存中读取的时间</strong>。<br>
以 x86 的 CPU 为例，矩阵在内存中是逐行存储的，一个 4x4 的矩阵 A 的存储顺序（由小到大）为</p>
<p>| 0 | 1 | 2 | 3 |<br>
| 4 | 5 | 6 | 7 |<br>
| 8 | 9 | A | B |<br>
| C | D | E | F |</p>
<p>假设该矩阵被分割成 2 个 2x2 的矩阵，在计算中需要逐列读取，那么第一个被读取的元素是 0 处的，第二个被读取的元素是 4 处的，他们的地址并不连续，这会浪费一定的寻址时间。因此，在 2x2 的分割下，需要针对该矩阵进行内存重排，重排后的顺序如下，这种重排叫做 zigzag，因为是按照之字型排序的。</p>
<p>| 0 | 2 | 4 | 6 |<br>
| 1 | 3 | 5 | 7 |<br>
| 8 | A | C | E |<br>
| 9 | B | D | F |</p>
</li>
</ol>
<h2 id="example"><a class="markdownIt-Anchor" href="#example">#</a> Example</h2>
<p>以 Megcc 生成的算子 <code>Arm64_fp32_m8_n12_mk4_matmul_NO_BIAS</code>  为例子，分析一下如何实现 gemm 优化过后的算子。这是按照 M8N12K4 的分割的，想象一个三维的长方体分割就可以。</p>
<ol>
<li>
<p><strong>重排内存</strong></p>
<p>kernel 的执行入口是 <code>void Arm64_fp32_m8_n12_mk4_matmul_NO_BIAS</code> ，该程序首先确认矩阵的内存空间。</p>
<ul>
<li>
<p>Code</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">size_t</span> pack_a_size = Arm64_fp32_m8_n12_mk4_matmul_NO_BIAS_workspace_a(<span class="number">0</span>, M, <span class="number">0</span>, K);</span><br><span class="line"><span class="type">float</span>* pack_a = workspace; # 矩阵A的开始地址</span><br><span class="line"><span class="type">float</span>* pack_b = workspace + pack_a_size; #矩阵B的开始地址</span><br><span class="line">Arm64_fp32_m8_n12_mk4_matmul_NO_BIAS_packa_n(pack_a, A, LDA, <span class="number">0</span>, M, <span class="number">0</span>, K); </span><br><span class="line"># 按照上述第<span class="number">4</span>步对矩阵进行重排</span><br><span class="line">Arm64_fp32_m8_n12_mk4_matmul_NO_BIAS_packb_n(pack_b, B, LDB, <span class="number">0</span>, N, <span class="number">0</span>, K); </span><br><span class="line"># 按照上述第<span class="number">4</span>步对矩阵进行重排</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<p><strong>矩阵计算</strong></p>
<p>矩阵的计算是逐 Block 进行的， M8N12K4 的计算方式中，每一个块的大小为 8x12x4。</p>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (; m + m_block &lt;= M; m += m_block) {</span><br><span class="line">        <span class="type">float</span>* output = C + (m / pack_mk * LDC);</span><br><span class="line"></span><br><span class="line">        <span class="type">size_t</span> n = <span class="number">0</span>;</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* cur_pack_b = pack_b;</span><br><span class="line">        <span class="keyword">for</span> (; n + n_block &lt;= N; n += n_block) {</span><br><span class="line">            kern_8x12_bias_relu(pack_a, cur_pack_b, K, output, LDC, _bias_ptr); # 每一个小block的计算</span><br><span class="line">            output += n_block * pack_mk;</span><br><span class="line">            ;</span><br><span class="line">            cur_pack_b += K12;</span><br><span class="line">        }</span><br><span class="line">        # 当n不能被<span class="number">12</span>整除时，剩下的n按照<span class="number">4</span>分割计算。</span><br><span class="line">        <span class="keyword">for</span> (; n &lt; N; n += <span class="number">4</span>) {</span><br><span class="line">            kern_8x4_bias_relu(</span><br><span class="line">                    pack_a, cur_pack_b, K, output, LDC, _bias_ptr,</span><br><span class="line">                    N - n &gt; <span class="number">4</span> ? <span class="number">4</span> : N - n); </span><br><span class="line">                    # 即使剩下的不能被<span class="number">4</span>整除也按照<span class="number">4</span>向上对齐处理。</span><br><span class="line">            output += <span class="number">4</span> * pack_mk;</span><br><span class="line">            ;</span><br><span class="line">            cur_pack_b += K4;</span><br><span class="line">        }</span><br><span class="line">        pack_a += K8;</span><br><span class="line">    }</span><br><span class="line">    #当m不能被<span class="number">8</span>整除时，剩下的m的维度按照<span class="number">4</span>整除计算。</span><br><span class="line">    <span class="keyword">for</span> (; m &lt; M; m += m_block_4) {</span><br><span class="line">        <span class="type">float</span>* output = C + (m / pack_mk * LDC);</span><br><span class="line"></span><br><span class="line">        <span class="type">size_t</span> n = <span class="number">0</span>;</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* cur_pack_b = pack_b;</span><br><span class="line">        <span class="keyword">for</span> (; n + n_block - <span class="number">1</span> &lt; N; n += n_block) {</span><br><span class="line">            kern_4x12_bias_relu(pack_a, cur_pack_b, K, output, LDC, _bias_ptr);</span><br><span class="line">            output += n_block * pack_mk;</span><br><span class="line">            ;</span><br><span class="line">            cur_pack_b += K12;</span><br><span class="line">        }</span><br><span class="line">        #同上</span><br><span class="line">        <span class="keyword">for</span> (; n &lt; N; n += <span class="number">4</span>) {</span><br><span class="line">            kern_4x4_bias_relu(</span><br><span class="line">                    pack_a, cur_pack_b, K, output, LDC, _bias_ptr,</span><br><span class="line">                    N - n &gt; <span class="number">4</span> ? <span class="number">4</span> : N - n);</span><br><span class="line">            output += <span class="number">4</span> * pack_mk;</span><br><span class="line">            ;</span><br><span class="line">            cur_pack_b += K4;</span><br><span class="line">        }</span><br><span class="line">        pack_a += K4;</span><br><span class="line">    }</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>汇编实现：内存重排</strong></p>
<p>对 A 进行内存重排的程序入口如下，矩阵 A 的形状为 [M/4, K/4, 4, 4]，如下图所示，A 矩阵在内存中首先以块顺序 0-7 存储，在每一块内按照 0-F 的顺序存储。对 A 进行内存重排后的形状为 [M/8, K, 8]，在图中为了方便理解，箭头方向为数据存储的方向，假设 M=16，K=8。</p>
 <center>
     <img src="/2024/07/19/%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96gemm%E7%AE%97%E5%AD%90/1.svg" style="width:99%">
 </center>
<p>以下程序描述了如何进行内存重排的过程。首先需要两个指针 <code>inptr0</code>  和 <code>inptr1</code>  定位原矩阵的内存，其中 <code>inptr0</code>  定位的是第 0 矩阵块（以下都称为块，描述的是上图中矩阵的分块情况）内存起点， <code>inptr1</code>  定位的是第 2 块内存起点， <code>prefetch_2x</code>  函数的作用是读取 32 个 fp32 数据，即 2 块，该函数将 0、1 和 2、3 块数据加载到缓存中， <code>interleave_2x4_4_s</code>  是重排函数，作用是将载入缓存的块数据重排，具体如何展开请看后续。注意，若 m 不被 8 整除，需要在下一个循环代码中处理尾部数据。</p>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">Arm64_fp32_m8_n12_mk4_matmul_NO_BIAS_packa_n</span><span class="params">(</span></span><br><span class="line"><span class="params">        <span class="type">float</span>* outptr, <span class="type">const</span> <span class="type">float</span>* inptr, <span class="type">int</span> ldin, <span class="type">int</span> y0, <span class="type">int</span> ymax, <span class="type">int</span> k0,</span></span><br><span class="line"><span class="params">        <span class="type">int</span> kmax)</span> {</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> pack_mk = <span class="number">4</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> pack_m = <span class="number">8</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> m_stride = pack_m * pack_mk;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> min_m_stride = pack_mk * pack_mk;</span><br><span class="line">    <span class="type">int</span> y = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (; y + <span class="number">7</span> &lt; ymax; y += pack_m) {</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* inptr0 = inptr + y / pack_mk * ldin;</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* inptr1 = inptr0 + ldin;</span><br><span class="line">        prefetch_2x(inptr0);</span><br><span class="line">        prefetch_2x(inptr1);</span><br><span class="line">        <span class="type">int</span> k = (kmax);</span><br><span class="line">        <span class="keyword">for</span> (; k &gt; <span class="number">3</span>; k -= pack_mk) {</span><br><span class="line">            interleave_2x4_4_s(inptr0, inptr1, outptr);</span><br><span class="line">            outptr += m_stride;</span><br><span class="line">            inptr0 += min_m_stride;</span><br><span class="line">            inptr1 += min_m_stride;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="meta"># m不被8整除</span></span><br><span class="line">    <span class="keyword">for</span> (; y &lt; ymax; y += pack_mk) {</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* inptr0 = inptr + y / pack_mk * ldin;</span><br><span class="line">        prefetch_2x(inptr0);</span><br><span class="line">        <span class="type">int</span> K = (kmax);</span><br><span class="line">        <span class="keyword">for</span> (; K &gt; <span class="number">3</span>; K -= pack_mk) {</span><br><span class="line">            interleave_1x4_4_s(inptr0, outptr);</span><br><span class="line">            outptr += min_m_stride;</span><br><span class="line">            inptr0 += min_m_stride;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>重排函数实现的重点是函数 <code>interleave_2x4_4_s</code>  ，下图描述了矩阵 A 内存重排的实现过程。其中 v0-v7 为寄存器。程序首先将数据加载到寄存器后，重排顺序后再输出到矩阵 A 的输出位置指针。</p>
 <center>
     <img src="/2024/07/19/%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96gemm%E7%AE%97%E5%AD%90/2.svg" style="width:99%">
 </center>
<p>对 B 实现内存重排的原理类似，其原始形状为 [K/4, N, 4]，重排后形状为 [N/12, K, 12]，其形状变化和内存排序如下图所示，和 A 相比，需要多进行一个类似转置的操作。如下图所示，该重排把一个 4x12 的矩阵块（第一块绿色，紫色，黄色的三块）重排成了一个 12x4 的矩阵块。</p>
 <center>
     <img src="/2024/07/19/%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96gemm%E7%AE%97%E5%AD%90/3.svg" style="width:99%">
 </center>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">Arm64_fp32_m8_n12_mk4_matmul_NO_BIAS_packb_n</span><span class="params">(</span></span><br><span class="line"><span class="params">        <span class="type">float</span>* outptr, <span class="type">const</span> <span class="type">float</span>* inptr, <span class="type">int</span> ldin, <span class="type">int</span> x0, <span class="type">int</span> xmax, <span class="type">int</span> k0,</span></span><br><span class="line"><span class="params">        <span class="type">int</span> kmax)</span> {</span><br><span class="line">    <span class="type">float</span> tmpbuff[<span class="number">16</span>] = {<span class="number">0.0f</span>};</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> PACK_C_SIZE = <span class="number">4</span>;</span><br><span class="line">    <span class="type">int</span> ksize = kmax - k0;</span><br><span class="line">    <span class="type">int</span> ksize12 = ksize * <span class="number">12</span>;</span><br><span class="line">    <span class="type">int</span> ksize4 = (ksize &lt;&lt; <span class="number">2</span>);</span><br><span class="line">    <span class="type">float</span>* outptr_base = outptr;</span><br><span class="line">    <span class="type">float</span>* outptr_base4 = outptr_base + (xmax - x0) / <span class="number">12</span> * ksize12;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> k = k0;</span><br><span class="line">    <span class="keyword">for</span> (; k + <span class="number">3</span> &lt; kmax; k += <span class="number">4</span>) {</span><br><span class="line">        <span class="type">const</span> <span class="type">float</span>* temp_inptr = inptr + k / PACK_C_SIZE * ldin + x0 * PACK_C_SIZE;</span><br><span class="line">        prefetch_3x(temp_inptr);</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> x = x0;</span><br><span class="line">        <span class="type">float</span>* temp_outptr = outptr_base;</span><br><span class="line">        <span class="keyword">for</span> (; x + <span class="number">12</span> &lt;= xmax; x += <span class="number">12</span>) {</span><br><span class="line">            <span class="type">float</span>* outptr_interleave = temp_outptr;</span><br><span class="line">            transpose_1x12_4_s(temp_inptr, outptr_interleave);</span><br><span class="line">            temp_outptr += ksize12;</span><br><span class="line">            temp_inptr += <span class="number">4</span> * <span class="number">12</span>;</span><br><span class="line">        }</span><br><span class="line">        temp_outptr = outptr_base4;</span><br><span class="line">        <span class="keyword">for</span> (; x + <span class="number">4</span> &lt;= xmax; x += <span class="number">4</span>) {</span><br><span class="line">            <span class="type">float</span>* outptr_interleave = temp_outptr;</span><br><span class="line">            <span class="keyword">asm</span> <span class="title function_">volatile</span><span class="params">(</span></span><br><span class="line"><span class="params">                    <span class="string">"ld4 {v0.4s, v1.4s, v2.4s, v3.4s},  [%[inptr0]], #64\n"</span></span></span><br><span class="line"><span class="params">                    <span class="string">"st1 {v0.4s, v1.4s, v2.4s, v3.4s},  [%[outptr0]]\n"</span></span></span><br><span class="line"><span class="params">                    : [inptr0] <span class="string">"+r"</span>(temp_inptr), [outptr0] <span class="string">"+r"</span>(outptr_interleave)</span></span><br><span class="line"><span class="params">                    :</span></span><br><span class="line"><span class="params">                    : <span class="string">"v0"</span>, <span class="string">"v1"</span>, <span class="string">"v2"</span>, <span class="string">"v3"</span>, <span class="string">"memory"</span>)</span>;</span><br><span class="line">            temp_outptr += ksize4;</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span> (x &lt; xmax) {</span><br><span class="line">            <span class="built_in">memcpy</span>(tmpbuff, temp_inptr, <span class="keyword">sizeof</span>(<span class="type">float</span>) * (xmax - x) * PACK_C_SIZE);</span><br><span class="line">            <span class="type">float</span>* outptr_interleave = temp_outptr;</span><br><span class="line">            <span class="type">const</span> <span class="type">float</span>* tmp_ptr = &amp;tmpbuff[<span class="number">0</span>];</span><br><span class="line">            <span class="keyword">asm</span> <span class="title function_">volatile</span><span class="params">(</span></span><br><span class="line"><span class="params">                    <span class="string">"ld4 {v0.4s, v1.4s, v2.4s, v3.4s},  [%[inptr0]], #64\n"</span></span></span><br><span class="line"><span class="params">                    <span class="string">"st1 {v0.4s, v1.4s, v2.4s, v3.4s},  [%[outptr0]]\n"</span></span></span><br><span class="line"><span class="params">                    : [inptr0] <span class="string">"+r"</span>(tmp_ptr), [outptr0] <span class="string">"+r"</span>(outptr_interleave)</span></span><br><span class="line"><span class="params">                    :</span></span><br><span class="line"><span class="params">                    : <span class="string">"v0"</span>, <span class="string">"v1"</span>, <span class="string">"v2"</span>, <span class="string">"v3"</span>, <span class="string">"memory"</span>)</span>;</span><br><span class="line">            temp_outptr += ksize4;</span><br><span class="line">        }</span><br><span class="line">        outptr_base += <span class="number">12</span> * <span class="number">4</span>;</span><br><span class="line">        outptr_base4 += <span class="number">4</span> * <span class="number">4</span>;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>汇编实现: kernel func</strong></p>
<p>根据实现细节，实现一个 M8N12K4 的算子需要以下几个分层运算函数: <code>kern_8x12_bias_relu</code> , <code>kern_8x4_bias_relu</code> , <code>kern_4x12_bias_relu</code> , <code>kern_4x4_bias_relu</code> , 这些都是基于汇编语言实现的。以主要的 <code>kern_8x12_bias_relu</code>  为例子，来看一下这个函数是如何实现分层计算的。<br>
需要理解的汇编语言操作如下表</p>
<ol>
<li>eor   异或操作</li>
<li>ld1   从内存中加载数据</li>
<li>prfm  预取内存到缓存</li>
<li>cmp   比较操作符</li>
<li>fmla  向量乘加操作</li>
<li>bne   比较结果不相等时跳转</li>
<li>st1   将寄存器的数据写入内存</li>
</ol>
<p>根据优化思路的第 2 步，首先你需要加载 A 的 8 个元素（2 个寄存器）和 B 的 12 个元素（3 个寄存器）到 cache 中，再为中间结果矩阵准备 24 个寄存器。<br>
在以下这段汇编代码中，首先通过异或操作 <code>eor</code>  清空了 8-31 寄存器的所有字节（x.16b），一共 24 个，这些寄存器是为了存储中间结果准备的。用 output0 和 output1 两个指针作为输出，并通过 <code>prfm</code>  把他们预取到缓存中。以下是汇编代码的主体实现，实际使用时，arm 架构有 32 个 128 位的寄存器，除去以上的 29 个，另外空闲的 3 个处理器分给 B 做数据的预取。</p>
<ul>
<li>
<p>Code</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"eor  v8.16b, v8.16b, v8.16b     \n"</span> # 清空v8寄存器，下同</span><br><span class="line"><span class="string">"eor  v9.16b, v9.16b, v9.16b     \n"</span></span><br><span class="line"><span class="string">"eor  v10.16b, v10.16b, v10.16b  \n"</span></span><br><span class="line"><span class="string">"prfm pstl1keep, [%[output0]]    \n"</span> # 预取</span><br><span class="line"><span class="string">"eor  v11.16b, v11.16b, v11.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v12.16b, v12.16b, v12.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v13.16b, v13.16b, v13.16b  \n"</span></span><br><span class="line"><span class="string">"prfm pstl1keep, [%[output1]]    \n"</span></span><br><span class="line"><span class="string">"eor  v14.16b, v14.16b, v14.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v15.16b, v15.16b, v15.16b  \n"</span></span><br><span class="line"><span class="string">"ld1 {v2.4s}, [%[b_ptr]], #16    \n"</span> # v2加载B的四个字节，同时将指针向后移<span class="number">16</span>个字节</span><br><span class="line"><span class="string">"eor  v16.16b, v16.16b, v16.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v17.16b, v17.16b, v17.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v18.16b, v18.16b, v18.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v19.16b, v19.16b, v19.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v20.16b, v20.16b, v20.16b  \n"</span></span><br><span class="line"><span class="string">"ld1 {v3.4s}, [%[b_ptr]], #16    \n"</span> # v3加载B的四个字节，同时将指针向后移<span class="number">16</span>个字节</span><br><span class="line"><span class="string">"eor  v21.16b, v21.16b, v21.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v22.16b, v22.16b, v22.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v23.16b, v23.16b, v23.16b  \n"</span></span><br><span class="line"><span class="string">"ld1 {v4.4s}, [%[b_ptr]], #16    \n"</span> # v4加载B的四个字节，同时将指针向后移<span class="number">16</span>个字节</span><br><span class="line"><span class="string">"eor  v24.16b, v24.16b, v24.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v25.16b, v25.16b, v25.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v26.16b, v26.16b, v26.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v27.16b, v27.16b, v27.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v28.16b, v28.16b, v28.16b  \n"</span></span><br><span class="line"><span class="string">"ld1 {v0.4s}, [%[a_ptr]], #16    \n"</span># v0加载A的四个字节，同时将指针向后移<span class="number">16</span>个字节</span><br><span class="line"><span class="string">"eor  v29.16b, v29.16b, v29.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v30.16b, v30.16b, v30.16b  \n"</span></span><br><span class="line"><span class="string">"eor  v31.16b, v31.16b, v31.16b  \n"</span></span><br><span class="line"><span class="string">"2: \n"</span></span><br><span class="line"><span class="string">"cmp %w[K], #0\n"</span>   #如果k=<span class="number">0</span> 此时k=<span class="number">1</span></span><br><span class="line"><span class="string">"beq 4f\n"</span>          </span><br><span class="line"></span><br><span class="line"><span class="string">"3:\n"</span></span><br><span class="line"><span class="string">"fmla v8.4s,  v0.4s, v2.s[0]\n"</span>  # A的前四个元素和B的第一个元素相乘</span><br><span class="line"><span class="string">"fmla v9.4s,  v0.4s, v2.s[1]\n"</span>  # A的前四个元素和B的第二个元素相乘</span><br><span class="line"><span class="string">"ld1 {v1.4s}, [%[a_ptr]], 16\n"</span>  # v1加载A的四个字节，同时指针偏移</span><br><span class="line"><span class="string">"fmla v10.4s, v0.4s, v2.s[2]\n"</span>  # A的前四个元素和B的第三个元素相乘</span><br><span class="line"><span class="string">"fmla v11.4s, v0.4s, v2.s[3]\n"</span>  # A的前四个元素和B的第四个元素相乘</span><br><span class="line"><span class="string">"ld1 {v5.4s}, [%[b_ptr]], #16\n"</span>   # v5加载B的四个字节，同时指针偏移</span><br><span class="line"><span class="string">"fmla v12.4s, v0.4s, v3.s[0]\n"</span></span><br><span class="line"><span class="string">"fmla v13.4s, v0.4s, v3.s[1]\n"</span></span><br><span class="line"><span class="string">"ld1 {v6.4s}, [%[b_ptr]], #16\n"</span> # v6加载B的四个字节，同时指针偏移</span><br><span class="line"><span class="string">"fmla v14.4s, v0.4s, v3.s[2]\n"</span></span><br><span class="line"><span class="string">"fmla v15.4s, v0.4s, v3.s[3]\n"</span></span><br><span class="line"><span class="string">"ld1 {v7.4s}, [%[b_ptr]], #16\n"</span> # v7加载B的四个字节，同时指针偏移</span><br><span class="line"><span class="string">"fmla v16.4s, v0.4s, v4.s[0]\n"</span></span><br><span class="line"><span class="string">"fmla v17.4s, v0.4s, v4.s[1]\n"</span></span><br><span class="line"><span class="string">"fmla v18.4s, v0.4s, v4.s[2]\n"</span></span><br><span class="line"><span class="string">"fmla v19.4s, v0.4s, v4.s[3]\n"</span></span><br><span class="line"><span class="string">"ld1 {v0.4s}, [%[a_ptr]], 16\n"</span> # 此时A的前四个元素的计算完成，向后加载<span class="number">4</span>个字节</span><br><span class="line"></span><br><span class="line"><span class="string">"fmla v20.4s, v1.4s, v2.s[0]\n"</span> </span><br><span class="line"><span class="string">"fmla v21.4s, v1.4s, v2.s[1]\n"</span></span><br><span class="line"><span class="string">"fmla v22.4s, v1.4s, v2.s[2]\n"</span></span><br><span class="line"><span class="string">"fmla v23.4s, v1.4s, v2.s[3]\n"</span></span><br><span class="line"><span class="string">"fmla v24.4s, v1.4s, v3.s[0]\n"</span></span><br><span class="line"><span class="string">"fmla v25.4s, v1.4s, v3.s[1]\n"</span></span><br><span class="line"><span class="string">"fmla v26.4s, v1.4s, v3.s[2]\n"</span></span><br><span class="line"><span class="string">"fmla v27.4s, v1.4s, v3.s[3]\n"</span></span><br><span class="line"><span class="string">"fmla v28.4s, v1.4s, v4.s[0]\n"</span></span><br><span class="line"><span class="string">"fmla v29.4s, v1.4s, v4.s[1]\n"</span></span><br><span class="line"><span class="string">"fmla v30.4s, v1.4s, v4.s[2]\n"</span></span><br><span class="line"><span class="string">"fmla v31.4s, v1.4s, v4.s[3]\n"</span> </span><br><span class="line"></span><br><span class="line"><span class="string">"fmla v8.4s,  v0.4s, v5.s[0]\n"</span></span><br><span class="line"><span class="string">"fmla v9.4s,  v0.4s, v5.s[1]\n"</span></span><br><span class="line"><span class="string">"ld1 {v1.4s}, [%[a_ptr]], 16\n"</span> # 此时A的第一个<span class="number">8</span>x1的矩阵计算完毕，向后加载<span class="number">4</span>个字节</span><br><span class="line"><span class="string">"fmla v10.4s, v0.4s, v5.s[2]\n"</span></span><br><span class="line"><span class="string">"fmla v11.4s, v0.4s, v5.s[3]\n"</span></span><br><span class="line"><span class="string">"ld1 {v2.4s}, [%[b_ptr]], 16\n"</span></span><br><span class="line"><span class="string">"fmla v12.4s, v0.4s, v6.s[0]\n"</span></span><br><span class="line"><span class="string">"fmla v13.4s, v0.4s, v6.s[1]\n"</span></span><br><span class="line"><span class="string">"ld1 {v3.4s}, [%[b_ptr]], 16\n"</span></span><br><span class="line"><span class="string">"fmla v14.4s, v0.4s, v6.s[2]\n"</span></span><br><span class="line"><span class="string">"fmla v15.4s, v0.4s, v6.s[3]\n"</span></span><br><span class="line"><span class="string">"ld1 {v4.4s}, [%[b_ptr]], 16\n"</span> # B也向后加载一个<span class="number">1</span>x12的矩阵分块</span><br><span class="line"><span class="string">"fmla v16.4s, v0.4s, v7.s[0]\n"</span></span><br><span class="line"><span class="string">"fmla v17.4s, v0.4s, v7.s[1]\n"</span></span><br><span class="line"><span class="string">"fmla v18.4s, v0.4s, v7.s[2]\n"</span></span><br><span class="line"><span class="string">"fmla v19.4s, v0.4s, v7.s[3]\n"</span></span><br><span class="line"><span class="string">"ld1 {v0.4s}, [%[a_ptr]], 16\n"</span> # 同上</span><br><span class="line"></span><br><span class="line"><span class="string">"fmla v20.4s, v1.4s, v5.s[0]\n"</span></span><br><span class="line"><span class="string">"fmla v21.4s, v1.4s, v5.s[1]\n"</span></span><br><span class="line"><span class="string">"fmla v22.4s, v1.4s, v5.s[2]\n"</span></span><br><span class="line"><span class="string">"fmla v23.4s, v1.4s, v5.s[3]\n"</span></span><br><span class="line"><span class="string">"fmla v24.4s, v1.4s, v6.s[0]\n"</span></span><br><span class="line"><span class="string">"subs %w[K], %w[K], #1\n"</span> #处理K的大小</span><br><span class="line"><span class="string">"fmla v25.4s, v1.4s, v6.s[1]\n"</span></span><br><span class="line"><span class="string">"fmla v26.4s, v1.4s, v6.s[2]\n"</span></span><br><span class="line"><span class="string">"fmla v27.4s, v1.4s, v6.s[3]\n"</span></span><br><span class="line"><span class="string">"fmla v28.4s, v1.4s, v7.s[0]\n"</span></span><br><span class="line"><span class="string">"fmla v29.4s, v1.4s, v7.s[1]\n"</span></span><br><span class="line"><span class="string">"fmla v30.4s, v1.4s, v7.s[2]\n"</span></span><br><span class="line"><span class="string">"fmla v31.4s, v1.4s, v7.s[3]\n"</span></span><br><span class="line"></span><br><span class="line"><span class="string">"bne 3b\n"</span></span><br><span class="line"></span><br><span class="line"># 后面是一些处理尾部的代码块，此处略</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
</div><div class="article-licensing box"><div class="licensing-title"><p>如何优化gemm算子</p><p><a href="http://example.com/2024/07/19/如何优化gemm算子/">http://example.com/2024/07/19/如何优化gemm算子/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>lcy</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2024-07-19</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2024-07-19</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/ospp/">ospp</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/04/24/2023-04-reading-record/"><span class="level-item">2023-04-reading-record</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><div class="column column-right  order-3"><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/favicon.svg" alt="lcy&#039;s blog" height="28"></a><p class="is-size-7"><span>&copy; 2025 lcy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>