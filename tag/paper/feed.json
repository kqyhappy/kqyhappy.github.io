{
    "version": "https://jsonfeed.org/version/1",
    "title": "lcy's blog • All posts by \"paper\" tag",
    "description": "学习/科研/生活/阅读",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2023/01/14/Paper-ATC-2022-GPULet/",
            "url": "http://example.com/2023/01/14/Paper-ATC-2022-GPULet/",
            "title": "Paper-ATC'2022-GPULet",
            "date_published": "2023-01-14T13:16:46.000Z",
            "content_html": "<p>link: <a href=\"https://www.usenix.org/conference/atc22/presentation/choi-seungbeom\">Serving Heterogeneous Machine Learning Models on Multi-GPU Servers with Spatio-Temporal Sharing | USENIX</a></p>\n<span id=\"more\"></span>\n<center>\n<img src=\"/2023/01/14/Paper-ATC-2022-GPULet/system-overview.jpg\" style=\"padding:5px; display:inline;\" width=\"90%\">\n</center>\n<h3 id=\"abstract\"><a class=\"markdownIt-Anchor\" href=\"#abstract\">#</a> Abstract</h3>\n<p>本文以<strong>最大化资源利用率</strong>和<strong>任务吞吐量</strong>为目标，为多模型推断的 GPU 集群实现了一个在线推断请求调度框架，在物理 GPU 与在线的请求之间设计了 GPULet Scheduler 工具来将 GPU 的计算资源分割成 GPULet，在分割计算资源时，本文综合考虑了<strong>时间</strong>、<strong>空间</strong>上的 GPU 资源，以及每次处理请求的<strong>批次</strong>大小，并且将搜索成本降低到了实际的在线系统可接受的范围。该系统在处理多 DNN 场景时能够<strong>自发调节使用的 GPU 个数</strong>以节约资源，另外，该系统额外考虑到了不同的 DNN Model 在 GPU 上的并行推断产生的冲突问题，建立了干扰预测模型。</p>\n<h3 id=\"introduction\"><a class=\"markdownIt-Anchor\" href=\"#introduction\">#</a> Introduction</h3>\n<p>CPU 上下文切换的速度是微秒级别，而 GPU 是毫秒的级别。</p>\n<h3 id=\"background\"><a class=\"markdownIt-Anchor\" href=\"#background\">#</a> Background</h3>\n<p>在 Background 章节，作者从三个维度阐述了提高 GPU 利用率的方法。</p>\n<ul>\n<li>\n<p>Batching-Aware ML Inference Serving</p>\n<p>与预先加载好数据的模型训练相比，模型推断不能实现 GPU 资源的高利用率的原因是在在线推断场景中，推断请求是在线产生的。人为地设置 GPU 处理推断任务时的批次大小，可以提高 GPU 内核的利用率。</p>\n</li>\n<li>\n<p>Temporal Scheduling for ML on GPUs</p>\n<p>作者介绍了<strong> Nexus</strong>，通过将 GPU 资源在时间上分片提供给不同批大小的模型来提高 GPU 的利用效率。</p>\n<p><strong>Nexus</strong> 采用<strong> SBP</strong> 算法。</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/temporal-sharing.jpg\" width=\"80%\">\n</center>\n</li>\n<li>\n<p>Spatial Sharing on GPU</p>\n<p>作者介绍了<strong> GSLICE</strong>，它的逻辑是根据推断结果的反馈来调整各个分区的资源占比，确定资源占比后启发式地调整批处理的大小，但 GSLICE 只针对单个 GPU。</p>\n</li>\n</ul>\n<p>本文的目标是在<strong>空间</strong>、<strong>时间</strong>以及<strong>批次大小</strong>三维的基础分割 GPU 资源实现<strong>最大化资源利用率</strong>和<strong>最小化使用 GPU</strong>。作者在 background 章节另外提出了本文的两个 baseline，分别是时间 baseline 的<strong> SBP</strong> 算法和空间 baseline 的<strong> Greedy best-fit</strong> 算法。</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/t-s.jpg\" width=\"80%\">\n</center>\n<h3 id=\"motivation\"><a class=\"markdownIt-Anchor\" href=\"#motivation\">#</a> Motivation</h3>\n<ul>\n<li>\n<p>Pre-Experiment-1：推断任务的最佳<strong>批</strong>大小与 GPU 的<strong>空间分区</strong>之间存在紧密的联系。</p>\n<p>作者选取不同的模型</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig4.jpg\" width=\"80%\">\n</center>\n</li>\n<li>\n<p>Pre-Experiment-2：<strong>时 / 空 / 批</strong>三维的搜索空间得到的推断任务调度最优解比<strong>时 / 批</strong>二维的搜索空间得到的推断任务调度最优解更优。</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/3d-search.jpg\" width=\"80%\">\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig5.jpg\" width=\"80%\">\n</center>\n</li>\n<li>\n<p>Pre-Experiment-3：在<strong>有效分割</strong>的前提下，时空 GPU 资源调度可以有效提高 GPU 的资源利用率，提高系统的吞吐量。</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig6.jpg\" width=\"80%\">\n</center>\n</li>\n<li>\n<p>Pre-Experiment-4：<strong>不同</strong>的 Model 同时在一个 GPU 上进行推断任务时，由于存在<strong>资源争用</strong>问题，并行执行可能会存在额外的<strong>干扰</strong>开销。</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig7.jpg\" width=\"80%\">\n</center>\n</li>\n</ul>\n<h3 id=\"design\"><a class=\"markdownIt-Anchor\" href=\"#design\">#</a> Design</h3>\n<ul>\n<li>\n<p>GPULet</p>\n<p>为了给不同的模型分配的 GPU 资源，作者引入了<strong> Gpulet</strong>，Gpulet 是建立在物理 GPU 上的一个虚拟的 GPU，它是 GPU 在<strong>空间</strong>和<strong>时间</strong>上分配的计算资源的集成。</p>\n<blockquote>\n<p>For each trained ML model, a minimal performance profile is collected offline.</p>\n</blockquote>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/gpulet.jpg\" width=\"80%\">\n</center>\n</li>\n<li>\n<p>Overview</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig8.jpg\" width=\"80%\">\n</center>\n<p><strong>Request Monitor：<strong>监视不同 Model 的 Request 频率，作为调度器调度的</strong>参考变量</strong>之一。</p>\n<p>**Gpulet Scheduler：** 综合配置文件中不同 Model 的时延、SLO 要求、Request 的到达频率，决定</p>\n<ul>\n<li>该 Model 的 Request 以何种<strong>批次大小</strong>执行。</li>\n<li>该 Model 的 Request 在<strong>哪块 GPU</strong> 上执行。</li>\n<li>该 Model 的 Request 在 GPU 的<strong>空间分区、时间分区</strong>的资源占用情况。</li>\n</ul>\n<p>**Partition Manager：** 实现 GPU 的分区，并且周期性的根据 Request 的 Rate 进行调整。</p>\n<p>**Executor：** 实现 Scheduler 的决策，将 Request 分配到不同的 Gpulet 上执行。</p>\n</li>\n<li>\n<p>Challenge-1: Achieve Cost-effective scheduling</p>\n<p>本文实现的核心调度算法，目标是<strong>最大化系统的吞吐量</strong>的同时<strong>最小化资源消耗</strong>。相比二维的情况，三维显著增加了调度的搜索空间，因此作者引入了配置文件，记录了 Model 在不同的 batch size 下不同的<strong> Gpu 空间分区</strong>的时延大小。</p>\n</li>\n<li>\n<p>Challenge-2: Dynamic reorganization</p>\n<p>当 Model 的 Request Rate 发生变化时，触发 GPULet 的<strong>重新调度</strong>。在 Gpu 上实现新的分区需要一定的代价开销，原文引用如下。解决的方法是周期性地</p>\n<blockquote>\n<p>Preparing a new partition includes spawning a new process, loading kernels used by PyTorch, loading required models, and warming up.</p>\n</blockquote>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig11.jpg\" width=\"80%\">\n</center>\n</li>\n<li>\n<p>Challenge-3: Interference prediction</p>\n<p>量化不同的模型在同一个物理的 GPU 上并行处理时的<strong>时延干扰损失</strong>，作者在衡量多个因素后选取了两个重要因素，通过<strong>线性回归</strong>判定 Model A 和 Model B 在同一块物理 GPU 上并行执行时的时延的<strong>额外开销</strong>，实验证明该错误率在 10% 左右。</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/interference.jpg\" width=\"80%\">\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig10.jpg\" width=\"80%\">\n</center>\n</li>\n</ul>\n<h3 id=\"evaluation\"><a class=\"markdownIt-Anchor\" href=\"#evaluation\">#</a> Evaluation</h3>\n<h3 id=\"conclusion\"><a class=\"markdownIt-Anchor\" href=\"#conclusion\">#</a> Conclusion</h3>\n",
            "tags": [
                "paper"
            ]
        }
    ]
}