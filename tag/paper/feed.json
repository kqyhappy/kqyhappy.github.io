{
    "version": "https://jsonfeed.org/version/1",
    "title": "lcy's blog • All posts by \"paper\" tag",
    "description": "学习/科研/生活/阅读",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2023/01/14/Paper-ATC-2022-GPULet/",
            "url": "http://example.com/2023/01/14/Paper-ATC-2022-GPULet/",
            "title": "Paper-ATC'2022-GPULet",
            "date_published": "2023-01-14T13:16:46.000Z",
            "content_html": "<p>link: <a href=\"https://www.usenix.org/conference/atc22/presentation/choi-seungbeom\">Serving Heterogeneous Machine Learning Models on Multi-GPU Servers with Spatio-Temporal Sharing | USENIX</a></p>\n<span id=\"more\"></span>\n\n<center>\n<img src=\"/2023/01/14/Paper-ATC-2022-GPULet/system-overview.jpg\" style=\"padding:5px; display:inline;\" width=\"90%\">\n</center>\n\n\n<h3 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h3><p>本文以<strong>最大化资源利用率</strong>和<strong>任务吞吐量</strong>为目标，为多模型推断的GPU集群实现了一个在线推断请求调度框架，在物理GPU与在线的请求之间设计了GPULet Scheduler工具来将GPU的计算资源分割成GPULet，在分割计算资源时，本文综合考虑了<strong>时间</strong>、<strong>空间</strong>上的GPU资源，以及每次处理请求的<strong>批次</strong>大小，并且将搜索成本降低到了实际的在线系统可接受的范围。该系统在处理多DNN场景时能够<strong>自发调节使用的GPU个数</strong>以节约资源，另外，该系统额外考虑到了不同的DNN Model在GPU上的并行推断产生的冲突问题，建立了干扰预测模型。</p>\n<h3 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h3><p>CPU上下文切换的速度是微秒级别，而GPU是毫秒的级别。</p>\n<h3 id=\"Background\"><a href=\"#Background\" class=\"headerlink\" title=\"Background\"></a>Background</h3><p>在Background章节，作者从三个维度阐述了提高GPU利用率的方法。</p>\n<ul>\n<li><p>Batching-Aware ML Inference Serving</p>\n<p>与预先加载好数据的模型训练相比，模型推断不能实现GPU资源的高利用率的原因是在在线推断场景中，推断请求是在线产生的。人为地设置GPU处理推断任务时的批次大小，可以提高GPU内核的利用率。</p>\n</li>\n<li><p>Temporal Scheduling for ML on GPUs</p>\n<p>作者介绍了<strong>Nexus</strong>，通过将GPU资源在时间上分片提供给不同批大小的模型来提高GPU的利用效率。</p>\n<p><strong>Nexus</strong>采用<strong>SBP</strong>算法。</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/temporal-sharing.jpg\" width=\"80%\">\n</center>\n\n</li>\n<li><p>Spatial Sharing on GPU</p>\n<p>作者介绍了<strong>GSLICE</strong>，它的逻辑是根据推断结果的反馈来调整各个分区的资源占比，确定资源占比后启发式地调整批处理的大小，但GSLICE只针对单个GPU。</p>\n</li>\n</ul>\n<p>本文的目标是在<strong>空间</strong>、<strong>时间</strong>以及<strong>批次大小</strong>三维的基础分割GPU资源实现<strong>最大化资源利用率</strong>和<strong>最小化使用GPU</strong>。作者在background章节另外提出了本文的两个baseline，分别是时间baseline的<strong>SBP</strong>算法和空间baseline的<strong>Greedy best-fit</strong>算法。</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/t-s.jpg\" width=\"80%\">\n</center>\n\n<h3 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h3><ul>\n<li><p>Pre-Experiment-1：推断任务的最佳<strong>批</strong>大小与GPU的<strong>空间分区</strong>之间存在紧密的联系。</p>\n<p>作者选取不同的模型</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig4.jpg\" width=\"80%\">\n</center>\n</li>\n<li><p>Pre-Experiment-2：<strong>时&#x2F;空&#x2F;批</strong>三维的搜索空间得到的推断任务调度最优解比<strong>时&#x2F;批</strong>二维的搜索空间得到的推断任务调度最优解更优。</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/3d-search.jpg\" width=\"80%\">\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig5.jpg\" width=\"80%\">\n</center>\n</li>\n<li><p>Pre-Experiment-3：在<strong>有效分割</strong>的前提下，时空GPU资源调度可以有效提高GPU的资源利用率，提高系统的吞吐量。</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig6.jpg\" width=\"80%\">\n</center>\n</li>\n<li><p>Pre-Experiment-4：<strong>不同</strong>的Model同时在一个GPU上进行推断任务时，由于存在<strong>资源争用</strong>问题，并行执行可能会存在额外的<strong>干扰</strong>开销。</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig7.jpg\" width=\"80%\">\n</center></li>\n</ul>\n<h3 id=\"Design\"><a href=\"#Design\" class=\"headerlink\" title=\"Design\"></a>Design</h3><ul>\n<li><p>GPULet</p>\n<p>为了给不同的模型分配的GPU资源，作者引入了<strong>Gpulet</strong>，Gpulet是建立在物理GPU上的一个虚拟的GPU，它是GPU在<strong>空间</strong>和<strong>时间</strong>上分配的计算资源的集成。</p>\n<blockquote>\n<p>For each trained ML model, a minimal performance profile is collected offline.</p>\n</blockquote>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/gpulet.jpg\" width=\"80%\">\n</center>\n</li>\n<li><p>Overview</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig8.jpg\" width=\"80%\">\n</center>\n\n<p><strong>Request Monitor：</strong>监视不同Model的Request频率，作为调度器调度的<strong>参考变量</strong>之一。</p>\n<p><strong>Gpulet Scheduler：</strong>综合配置文件中不同Model的时延、SLO要求、Request的到达频率，决定</p>\n<ul>\n<li>该Model的Request以何种<strong>批次大小</strong>执行。</li>\n<li>该Model的Request在<strong>哪块GPU</strong>上执行。</li>\n<li>该Model的Request在GPU的<strong>空间分区、时间分区</strong>的资源占用情况。</li>\n</ul>\n<p><strong>Partition Manager：</strong>实现GPU的分区，并且周期性的根据Request的Rate进行调整。</p>\n<p><strong>Executor：</strong>实现Scheduler的决策，将Request分配到不同的Gpulet上执行。</p>\n</li>\n<li><p>Challenge-1: Achieve Cost-effective scheduling</p>\n<p>本文实现的核心调度算法，目标是<strong>最大化系统的吞吐量</strong>的同时<strong>最小化资源消耗</strong>。相比二维的情况，三维显著增加了调度的搜索空间，因此作者引入了配置文件，记录了Model在不同的batch size下不同的<strong>Gpu空间分区</strong>的时延大小。</p>\n</li>\n<li><p>Challenge-2: Dynamic reorganization</p>\n<p>当Model的Request Rate发生变化时，触发GPULet的<strong>重新调度</strong>。在Gpu上实现新的分区需要一定的代价开销，原文引用如下。解决的方法是周期性地</p>\n<blockquote>\n<p>Preparing a new partition includes spawning a new process, loading kernels used by PyTorch, loading required models, and warming up.</p>\n</blockquote>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig11.jpg\" width=\"80%\">\n</center>\n</li>\n<li><p>Challenge-3: Interference prediction</p>\n<p>量化不同的模型在同一个物理的GPU上并行处理时的<strong>时延干扰损失</strong>，作者在衡量多个因素后选取了两个重要因素，通过<strong>线性回归</strong>判定Model A和Model B在同一块物理GPU上并行执行时的时延的<strong>额外开销</strong>，实验证明该错误率在10%左右。</p>\n<center>\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/interference.jpg\" width=\"80%\">\n    <img src=\"/2023/01/14/Paper-ATC-2022-GPULet/fig10.jpg\" width=\"80%\">\n</center></li>\n</ul>\n<h3 id=\"Evaluation\"><a href=\"#Evaluation\" class=\"headerlink\" title=\"Evaluation\"></a>Evaluation</h3><h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3>",
            "tags": [
                "paper"
            ]
        }
    ]
}